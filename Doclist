import os
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

template_dir = "path/to/templates"

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)

def extract_metadata(filename):
    lower = filename.lower()

    if lower.startswith("global"):
        return {
            "operator": "global",
            "category": "global"
        }
    elif lower.startswith("master_template_"):
        # Get operator code from file name
        operator = lower.replace("master_template_", "").replace(".txt", "")
        return {
            "operator": operator,
            "category": "operator"
        }
    else:
        return {
            "operator": "unknown",
            "category": "unknown"
        }

doclist = []

for filename in os.listdir(template_dir):
    if filename.endswith(".txt"):
        filepath = os.path.join(template_dir, filename)
        loader = TextLoader(filepath)
        raw_docs = loader.load()
        split_docs = text_splitter.split_documents(raw_docs)

        metadata = extract_metadata(filename)
        for doc in split_docs:
            doc.metadata.update(metadata)
            doc.metadata["source"] = filename

        doclist.extend(split_docs)
